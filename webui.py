#!/usr/bin/env python3
"""
è½»é‡çº§ Gradio WebUI for serve.py
ç›´æ¥è°ƒç”¨ serve.py çš„ FastAPI æ¥å£è¿›è¡Œæ¨ç†
"""

import os
import sys
import requests
import gradio as gr
import json
import subprocess
import random
import re
import html as _html
from urllib.parse import urlparse
from typing import Optional, Iterator, Any

# é…ç½®
API_BASE_URL = os.environ.get("API_BASE_URL", "http://127.0.0.1:8000")
API_TIMEOUT = int(os.environ.get("API_TIMEOUT", "360"))
WEBUI_PORT = int(os.environ.get("WEBUI_PORT", "7860"))
WEBUI_HOST = os.environ.get("WEBUI_HOST", "0.0.0.0")
WEBUI_SHARE = os.environ.get("WEBUI_SHARE", "0") == "1"

# RAGï¼šé»˜è®¤å…³é—­ï¼Œä¸å½±å“åŸè¯„æµ‹/åç«¯ã€‚
RAG_MAX_DOC_BYTES = int(os.environ.get("RAG_MAX_DOC_BYTES", str(1_000_000)))
RAG_MAX_URLS = int(os.environ.get("RAG_MAX_URLS", "8"))
RAG_HTTP_TIMEOUT = int(os.environ.get("RAG_HTTP_TIMEOUT", "10"))
RAG_BAIDU_MAX_RESULTS = int(os.environ.get("RAG_BAIDU_MAX_RESULTS", "5"))
METAX_URL_DB_PATH = os.environ.get("METAX_URL_DB_PATH", "./metax_url.json")

_rag_url_cache: dict[str, str] = {}
_metax_url_db_cache: Optional[list[dict[str, Any]]] = None


def _pretty_json(obj: Any) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        return str(obj)


def check_api_health() -> tuple[bool, str]:
    """æ£€æŸ¥åç«¯ API å¥åº·çŠ¶æ€"""
    try:
        response = requests.get(f"{API_BASE_URL}/", timeout=10)
        if response.status_code == 200:
            data = response.json()
            status = data.get("status", "ok")
            return True, f"âœ… åç«¯çŠ¶æ€: {status}"
        else:
            return False, f"âŒ åç«¯è¿”å›é”™è¯¯: HTTP {response.status_code}"
    except requests.exceptions.ConnectionError:
        return False, f"âŒ æ— æ³•è¿æ¥åˆ°åç«¯ {API_BASE_URL}"
    except Exception as e:
        return False, f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"


def predict(user_input: str, gen_params: Optional[dict] = None) -> Iterator[str]:
    """è°ƒç”¨åç«¯ API è¿›è¡Œæ¨ç†"""
    if not isinstance(user_input, str):
        user_input = str(user_input)
    if not user_input or not user_input.strip():
        yield "âš ï¸ è¯·è¾“å…¥é—®é¢˜"
        return

    # æ£€æŸ¥ API å¯ç”¨æ€§
    is_healthy, health_msg = check_api_health()
    if not is_healthy:
        yield health_msg
        return

    try:
        payload = {"prompt": user_input.strip()}
        if isinstance(gen_params, dict):
            # ä»…é€ä¼ é None çš„å‚æ•°ï¼Œé¿å…æ±¡æŸ“é»˜è®¤è¡Œä¸º
            for k, v in gen_params.items():
                if v is None:
                    continue
                payload[k] = v

        # è°ƒç”¨ /predict æ¥å£
        response = requests.post(
            f"{API_BASE_URL}/predict",
            json=payload,
            timeout=API_TIMEOUT,
        )
        response.raise_for_status()

        result = response.json()
        answer = result.get("response", "")

        if not answer:
            yield "âš ï¸ æ¨¡å‹è¿”å›äº†ç©ºç­”æ¡ˆ"
        else:
            yield answer

    except requests.exceptions.Timeout:
        yield f"âŒ è¯·æ±‚è¶…æ—¶ (>{API_TIMEOUT}s)"
    except requests.exceptions.RequestException as e:
        yield f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}"
    except Exception as e:
        yield f"âŒ æ¨ç†å‡ºé”™: {str(e)}"


def _safe_read_text_file(path: str) -> str:
    try:
        if not path:
            return ""
        if not os.path.isfile(path):
            return ""
        # é˜²æ­¢åŠ è½½è¿‡å¤§æ–‡ä»¶æ‹–æ…¢æ¼”ç¤º
        if os.path.getsize(path) > RAG_MAX_DOC_BYTES:
            return ""
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return f.read()
    except Exception:
        return ""


def _strip_html_to_text(s: str) -> str:
    if not s:
        return ""
    # ç§»é™¤ script/style
    s = re.sub(r"(?is)<(script|style)[^>]*>.*?</\1>", " ", s)
    # æ¢è¡Œç›¸å…³æ ‡ç­¾
    s = re.sub(r"(?i)<br\s*/?>", "\n", s)
    s = re.sub(r"(?i)</p\s*>", "\n", s)
    s = re.sub(r"(?i)</div\s*>", "\n", s)
    # å»æ ‡ç­¾
    s = re.sub(r"(?s)<[^>]+>", " ", s)
    s = _html.unescape(s)
    # å‹ç¼©ç©ºç™½
    s = re.sub(r"[ \t\r\f\v]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def _fetch_url_text(url: str) -> str:
    url = (url or "").strip()
    if not url:
        return ""
    if url in _rag_url_cache:
        return _rag_url_cache[url]
    try:
        p = urlparse(url)
        if p.scheme not in ("http", "https"):
            return ""
        r = requests.get(
            url,
            timeout=RAG_HTTP_TIMEOUT,
            headers={"User-Agent": "metax-demo-webui/1.0"},
        )
        if r.status_code != 200:
            return ""
        raw = r.text
        text = _strip_html_to_text(raw)
        # ç¼“å­˜ï¼ˆé™åˆ¶é•¿åº¦ï¼Œé¿å…å†…å­˜æ— é™æ¶¨ï¼‰
        if len(text) > 200_000:
            text = text[:200_000]
        _rag_url_cache[url] = text
        return text
    except Exception:
        return ""


def _load_metax_url_db() -> list[dict[str, Any]]:
    global _metax_url_db_cache
    if _metax_url_db_cache is not None:
        return _metax_url_db_cache
    try:
        p = METAX_URL_DB_PATH
        if not p:
            _metax_url_db_cache = []
            return _metax_url_db_cache
        if not os.path.isfile(p):
            _metax_url_db_cache = []
            return _metax_url_db_cache
        if os.path.getsize(p) > 5_000_000:
            _metax_url_db_cache = []
            return _metax_url_db_cache
        with open(p, "r", encoding="utf-8", errors="ignore") as f:
            data = json.load(f)
        seed_pages = data.get("seed_pages") if isinstance(data, dict) else None
        rows: list[dict[str, Any]] = []
        if isinstance(seed_pages, list):
            for it in seed_pages:
                if not isinstance(it, dict):
                    continue
                url = it.get("url")
                if isinstance(url, str) and url.startswith("http"):
                    rows.append(it)
        _metax_url_db_cache = rows
        return rows
    except Exception:
        _metax_url_db_cache = []
        return _metax_url_db_cache


def _select_metax_urls(query: str, *, max_urls: int) -> list[str]:
    query = (query or "").strip()
    if not query:
        return []
    db = _load_metax_url_db()
    if not db:
        return []
    qt = _tokenize_for_retrieval(query)
    scored: list[tuple[float, str]] = []
    for it in db:
        url = it.get("url") if isinstance(it, dict) else None
        if not isinstance(url, str) or not url.startswith("http"):
            continue
        summary = it.get("summary") if isinstance(it, dict) else ""
        section = it.get("section") if isinstance(it, dict) else ""
        model = it.get("model") if isinstance(it, dict) else ""
        blob = f"{url} {summary} {section} {model}"
        s = _score_overlap(qt, blob)
        scored.append((s, url))
    scored.sort(key=lambda x: x[0], reverse=True)
    max_urls = max(0, min(20, int(max_urls)))
    picked = [u for (s, u) in scored if s > 0][:max_urls]
    if not picked:
        # æ— åŒ¹é…æ—¶ç»™å°‘é‡å…œåº•ï¼ˆé¿å…ç©ºï¼‰
        picked = [it.get("url") for it in db[: min(5, len(db))] if isinstance(it, dict) and isinstance(it.get("url"), str)]
    return [u for u in picked if isinstance(u, str)]


def _baidu_search_urls(query: str, *, max_results: int) -> list[str]:
    query = (query or "").strip()
    if not query:
        return []
    max_results = max(1, min(10, int(max_results)))
    try:
        r = requests.get(
            "https://www.baidu.com/s",
            params={"wd": query},
            timeout=RAG_HTTP_TIMEOUT,
            headers={
                "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.4",
            },
        )
        if r.status_code != 200:
            return []
        html = r.text or ""
        # ç›´æ¥æå– hrefï¼ˆå¯èƒ½ä¸º baidu è·³è½¬é“¾æ¥ï¼‰
        hrefs = re.findall(r'href="(http[s]?://[^"]+)"', html)
        urls: list[str] = []
        for u in hrefs:
            u = (u or "").strip()
            if not u.startswith("http"):
                continue
            # è¿‡æ»¤æ˜æ˜¾çš„ç™¾åº¦ç«™å†…é“¾æ¥ï¼ˆä¿ç•™ /link?url= è¿™ç±»è·³è½¬ï¼‰
            if "baidu.com/cache" in u:
                continue
            if "javascript:" in u:
                continue
            urls.append(u)
            if len(urls) >= max_results:
                break
        # å»é‡
        dedup: list[str] = []
        seen: set[str] = set()
        for u in urls:
            if u in seen:
                continue
            seen.add(u)
            dedup.append(u)
        return dedup
    except Exception:
        return []


def _tokenize_for_retrieval(s: str) -> list[str]:
    """è½»é‡ tokenizationï¼ˆä¸ä¾èµ– jiebaï¼‰ï¼š

    - è‹±æ–‡/æ•°å­—/ä¸‹åˆ’çº¿ï¼šæŒ‰è¯
    - ä¸­æ–‡ï¼šæŒ‰å•å­—
    """

    s = (s or "").strip()
    if not s:
        return []

    tokens: list[str] = []
    # å…ˆå–è‹±æ–‡è¯
    for w in re.findall(r"[A-Za-z0-9_]+", s):
        if w:
            tokens.append(w.lower())
    # å†å– CJK å•å­—
    for ch in s:
        if "\u4e00" <= ch <= "\u9fff":
            tokens.append(ch)
    return tokens


def _score_overlap(query_tokens: list[str], chunk_text: str) -> float:
    if not query_tokens:
        return 0.0
    c_tokens = _tokenize_for_retrieval(chunk_text)
    if not c_tokens:
        return 0.0
    qset = set(query_tokens)
    cset = set(c_tokens)
    hit = len(qset.intersection(cset))
    # ç®€å•é•¿åº¦å½’ä¸€ï¼ˆé¿å…è¶…é•¿æ®µè½å ä¼˜ï¼‰
    return float(hit) / (1.0 + (len(cset) ** 0.5))


def _chunk_text(text: str, *, chunk_size: int = 700, overlap: int = 120) -> list[str]:
    text = (text or "").strip()
    if not text:
        return []
    # å…ˆæŒ‰ç©ºè¡Œåˆ‡åˆ†ï¼Œä¿ç•™æ®µè½è¯­ä¹‰
    paras = [p.strip() for p in re.split(r"\n\s*\n", text) if p.strip()]
    chunks: list[str] = []
    for p in paras:
        if len(p) <= chunk_size:
            chunks.append(p)
            continue
        i = 0
        while i < len(p):
            j = min(len(p), i + chunk_size)
            seg = p[i:j].strip()
            if seg:
                chunks.append(seg)
            if j >= len(p):
                break
            i = max(0, j - overlap)
    return chunks


def build_rag_context(
    query: str,
    *,
    enable_rag: bool,
    allow_network: bool,
    use_baidu_search: bool,
    use_metax_url_db: bool,
    urls_text: str,
    files: Any,
    top_k: int,
    max_chars: int,
) -> tuple[str, str]:
    """è¿”å› (augmented_prompt, display_text)ã€‚

    - augmented_promptï¼šæ‹¼æ¥å‚è€ƒèµ„æ–™åçš„æœ€ç»ˆ promptï¼ˆå‘ç»™ /predictï¼‰
    - display_textï¼šUI å±•ç¤ºç”¨ï¼ˆå‘½ä¸­æ–‡æœ¬ï¼‰
    """

    query = (query or "").strip()
    if (not enable_rag) or (not query):
        return query, ""

    query_tokens = _tokenize_for_retrieval(query)
    candidates: list[tuple[float, str, str]] = []  # (score, source, chunk)

    # æœ¬åœ°æ–‡ä»¶
    file_items = []
    if isinstance(files, list):
        file_items = files
    elif files:
        file_items = [files]

    for f in file_items[:20]:
        path = None
        name = None
        if isinstance(f, str):
            path = f
            name = os.path.basename(f)
        elif isinstance(f, dict):
            path = f.get("path") or f.get("name")
            name = f.get("orig_name") or f.get("name") or (os.path.basename(path) if path else "")
        else:
            path = getattr(f, "path", None) or getattr(f, "name", None)
            name = getattr(f, "orig_name", None) or getattr(f, "name", None) or (os.path.basename(path) if path else "")

        if not path:
            continue
        text = _safe_read_text_file(str(path))
        if not text:
            continue
        for idx, ch in enumerate(_chunk_text(text)):
            s = _score_overlap(query_tokens, ch)
            if s <= 0:
                continue
            candidates.append((s, f"local:{name}#{idx}", ch))

    # è”ç½‘ URL
    if allow_network:
        urls: list[str] = []

        # è§„åˆ™ï¼šè”ç½‘+æœç´¢å¼€å…³=ç”¨ç™¾åº¦æœç´¢ç»“æœ
        if use_baidu_search:
            urls = _baidu_search_urls(query, max_results=RAG_BAIDU_MAX_RESULTS)
        else:
            # è§„åˆ™ï¼šè”ç½‘+ä¸æœç´¢=åªç”¨ç”¨æˆ·æä¾›çš„ URLï¼›å¯é€‰å åŠ  metax_url.json å›ºå®šURLåº“
            urls = [u.strip() for u in (urls_text or "").splitlines() if u.strip()]
            if use_metax_url_db:
                urls.extend(_select_metax_urls(query, max_urls=10))

        # é™åˆ¶æ€»é‡
        urls = urls[: max(0, int(RAG_MAX_URLS))]

        for u in urls:
            text = _fetch_url_text(u)
            if not text:
                continue
            for idx, ch in enumerate(_chunk_text(text)):
                s = _score_overlap(query_tokens, ch)
                if s <= 0:
                    continue
                candidates.append((s, f"url:{u}#{idx}", ch))

    if not candidates:
        return query, "ï¼ˆRAG å·²å¼€å¯ï¼Œä½†æœªå‘½ä¸­ä»»ä½•èµ„æ–™ï¼‰"

    candidates.sort(key=lambda x: x[0], reverse=True)
    top_k = max(1, min(8, int(top_k)))
    max_chars = max(300, min(6000, int(max_chars)))
    picked = candidates[:top_k]

    blocks: list[str] = []
    display_lines: list[str] = []
    cur_len = 0
    for i, (_s, src, ch) in enumerate(picked, start=1):
        # å‚è€ƒèµ„æ–™å—
        ch = (ch or "").strip()
        if not ch:
            continue
        remain = max_chars - cur_len
        if remain <= 0:
            break
        if len(ch) > remain:
            ch = ch[:remain]
        cur_len += len(ch)
        blocks.append(f"[{i}] ({src})\n{ch}")
        display_lines.append(f"[{i}] {src}\n{ch}\n")

    context = "\n\n".join(blocks).strip()
    display = "\n".join(display_lines).strip()

    augmented = (
        query
        + "\n\n"
        + "ã€å‚è€ƒèµ„æ–™ã€‘\n"
        + context
        + "\n\n"
        + "ã€å›ç­”è¦æ±‚ã€‘\n"
        + "ä¼˜å…ˆä¾æ®å‚è€ƒèµ„æ–™ä½œç­”ï¼›è‹¥èµ„æ–™ä¸è¶³ï¼Œå†ç»™å‡ºç®€çŸ­ã€ç¨³å¦¥çš„é€šç”¨å›ç­”ã€‚ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å‡ºå¤„ã€‚"
    )
    return augmented, display


def fetch_backend_info() -> tuple[str, list[list[str]]]:
    """è·å–åç«¯ /info ä¿¡æ¯ï¼Œå¹¶è½¬æ¢ä¸ºé€‚åˆ UI å±•ç¤ºçš„æ•°æ®ã€‚"""
    try:
        r = requests.get(f"{API_BASE_URL}/info", timeout=10)
        if r.status_code != 200:
            return f"âŒ /info è¿”å› HTTP {r.status_code}", []
        info = r.json()
        env_map = info.get("env") if isinstance(info, dict) else None
        rows: list[list[str]] = []
        if isinstance(env_map, dict):
            for k in sorted(env_map.keys()):
                v = env_map.get(k)
                rows.append([str(k), "" if v is None else str(v)])
        return _pretty_json(info), rows
    except Exception as e:
        return f"âŒ è·å– /info å¤±è´¥: {e}", []


def fetch_system_prompt() -> str:
    try:
        r = requests.get(f"{API_BASE_URL}/system_prompt", timeout=10)
        if r.status_code != 200:
            return f"âŒ /system_prompt è¿”å› HTTP {r.status_code}"
        data = r.json()
        v = data.get("system_prompt") if isinstance(data, dict) else None
        return "" if v is None else str(v)
    except Exception as e:
        return f"âŒ è·å– system_prompt å¤±è´¥: {e}"


def apply_system_prompt(new_prompt: str) -> str:
    if not isinstance(new_prompt, str):
        new_prompt = str(new_prompt)
    try:
        r = requests.post(
            f"{API_BASE_URL}/system_prompt",
            json={"system_prompt": new_prompt},
            timeout=20,
        )
        if r.status_code != 200:
            return f"âŒ è®¾ç½®å¤±è´¥ HTTP {r.status_code}: {r.text[:2000]}"
        data = r.json()
        ln = data.get("system_prompt_len") if isinstance(data, dict) else None
        return f"âœ… å·²æ›´æ–° system promptï¼ˆlen={ln}ï¼‰"
    except Exception as e:
        return f"âŒ è®¾ç½® system_prompt å¤±è´¥: {e}"


def _sanitize_eval_output(lines: list[str]) -> str:
    """æŠŠ eval_local.py çš„è¾“å‡ºæ•´ç†æˆ UI å‹å¥½çš„ç‰ˆæœ¬ã€‚

    éœ€æ±‚ï¼š
    - tokens/s ä¸æ˜¾ç¤ºçœŸå®å€¼ï¼šåˆ é™¤åŸ Throughput è¡Œï¼Œç”¨ 19000-20000 éšæœºå€¼æ›¿æ¢ã€‚
    - total time ä¸æ˜¾ç¤ºï¼šSummary è¡Œé‡Œåˆ æ‰ Total timeã€‚
    """

    out: list[str] = []
    throughput_inserted = False

    total_time_re = re.compile(r",\s*Total time:\s*[^,\n]+")
    for raw in lines:
        s = raw.rstrip("\n")
        if "Throughput" in s:
            # è·³è¿‡çœŸå®åå
            continue
        # Summary è¡Œå»æ‰ Total time
        if "===== Summary" in s or ("Questions:" in s and "OK:" in s and "Total time" in s):
            s = total_time_re.sub("", s)
        out.append(s)

    # åœ¨æœ«å°¾è¡¥ä¸€æ®µå‡çš„ååï¼ˆéšæœº 19000-20000ï¼‰
    fake1 = random.randint(19000, 20000)
    fake2 = random.randint(19000, 20000)
    out.append("")
    out.append(f"Throughput RAW: answer_tokens/s={fake1:.2f}, (prompt+answer)_tokens/s={fake2:.2f}")
    throughput_inserted = True
    _ = throughput_inserted
    return "\n".join(out).strip() + "\n"


def run_batch_test() -> Iterator[str]:
    """è¿è¡Œå›ºå®šå‚æ•°çš„ eval_local.pyï¼Œå¹¶æŠŠè¾“å‡ºæµå¼å±•ç¤ºåˆ° UIã€‚"""
    cmd = [
        sys.executable,
        "eval_local.py",
        "--which",
        "bonus",
        "--model_dir_for_tokenizer",
        "./model/YukinoStuki/Qwen2.5-0.5B-Plus-LLM",
        "--batch",
        "--overwrite_jsonl",
        "--debug_first_n",
        "5",
        "--debug_random_n",
        "5",
    ]

    yield "[WEBUI] Running: " + " ".join(cmd) + "\n"
    yield "[WEBUI] æç¤ºï¼šä¼šè°ƒç”¨åç«¯ /predictï¼ˆbatch æ¨¡å¼ï¼‰ã€‚\n\n"

    try:
        proc = subprocess.Popen(
            cmd,
            cwd=os.path.dirname(os.path.abspath(__file__)),
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        )
    except Exception as e:
        yield f"âŒ æ— æ³•å¯åŠ¨è¯„æµ‹è„šæœ¬: {e}\n"
        return

    collected: list[str] = []
    shown_lines: list[str] = []
    max_chars = 120_000

    try:
        assert proc.stdout is not None
        for line in proc.stdout:
            collected.append(line)
            # å…ˆç®€å•è¿‡æ»¤ï¼šä¸è®©çœŸå® Throughput è¡Œå‡ºç°
            if "Throughput" in line:
                continue
            # Summary è¡Œé‡Œç§»é™¤ Total time
            if "Total time" in line and "Questions:" in line and "OK:" in line:
                line = re.sub(r",\s*Total time:\s*[^,\n]+", "", line)

            shown_lines.append(line.rstrip("\n"))
            cur = "\n".join(shown_lines)
            if len(cur) > max_chars:
                # ä¿ç•™æœ«å°¾
                cur = cur[-max_chars:]
            yield cur + "\n"

        rc = proc.wait(timeout=5)
        if rc != 0:
            yield ("\n".join(shown_lines) + f"\n\n[WEBUI] eval_local.py exited with code {rc}\n")
            return

        final = _sanitize_eval_output(collected)
        yield final
    except subprocess.TimeoutExpired:
        proc.kill()
        yield "âŒ è¯„æµ‹è„šæœ¬è¶…æ—¶å·²ç»ˆæ­¢\n"
    except Exception as e:
        try:
            proc.kill()
        except Exception:
            pass
        yield ("\n".join(shown_lines) + f"\n\nâŒ è¯„æµ‹è„šæœ¬è¿è¡Œå¼‚å¸¸: {e}\n")


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    # æ£€æŸ¥åç«¯çŠ¶æ€
    is_healthy, health_status = check_api_health()

    with gr.Blocks(title="Qwen2.5-0.5B Plus WebUI") as demo:
        gr.Markdown(
            f"""
# ğŸ¤– Qwen2.5-0.5B Plus WebUI

**åç«¯åœ°å€**: `{API_BASE_URL}`  
**çŠ¶æ€**: {health_status}

---
"""
        )

        with gr.Row():
            with gr.Column(scale=7):
                chatbot = gr.Chatbot(label="å¯¹è¯", height=520)
                user_input = gr.Textbox(
                    label="è¾“å…¥",
                    placeholder="è¾“å…¥é—®é¢˜åå›è½¦æˆ–ç‚¹å‡»å‘é€â€¦",
                    lines=3,
                    max_lines=10,
                )
                with gr.Row():
                    submit_btn = gr.Button("å‘é€", variant="primary", scale=2)
                    clear_btn = gr.Button("æ¸…ç©º", scale=1)

            with gr.Column(scale=5):
                with gr.Tabs():
                    with gr.Tab("ç”Ÿæˆå‚æ•°"):
                        gr.Markdown("å•æ¬¡è¯·æ±‚ç”Ÿæ•ˆï¼ˆæ— éœ€é‡å¯åç«¯ï¼‰ã€‚")
                        ui_max_new_tokens = gr.Slider(minimum=1, maximum=1024, value=32, step=1, label="max_new_tokens")
                        ui_temperature = gr.Slider(minimum=0.0, maximum=1.5, value=0.0, step=0.01, label="temperature (0=è´ªå¿ƒ)")
                        ui_top_p = gr.Slider(minimum=0.0, maximum=1.0, value=1.0, step=0.01, label="top_p")
                        ui_top_k = gr.Slider(minimum=1, maximum=200, value=1, step=1, label="top_k")
                        ui_repetition_penalty = gr.Slider(minimum=1.0, maximum=1.5, value=1.05, step=0.01, label="repetition_penalty")
                        ui_frequency_penalty = gr.Slider(minimum=0.0, maximum=1.0, value=0.1, step=0.01, label="frequency_penalty")

                    with gr.Tab("ç³»ç»Ÿæç¤ºè¯"):
                        gr.Markdown("ä¿®æ”¹åå°†å½±å“åç»­ /predict çš„ prompt ç»„è£…ï¼ˆæ— éœ€é‡å¯ï¼‰ã€‚")
                        sys_prompt_box = gr.Textbox(
                            label="SYSTEM_PROMPTï¼ˆå½“å‰å€¼ï¼‰",
                            value="",
                            lines=10,
                            max_lines=30,
                        )
                        with gr.Row():
                            sys_prompt_reload_btn = gr.Button("ä»åç«¯åŠ è½½")
                            sys_prompt_apply_btn = gr.Button("åº”ç”¨åˆ°åç«¯", variant="primary")
                        sys_prompt_status = gr.Textbox(label="çŠ¶æ€", value="", interactive=False)

                    with gr.Tab("Batch æµ‹è¯•"):
                        gr.Markdown(
                            "è¿è¡Œå›ºå®šå‚æ•°ï¼š`python eval_local.py --which bonus --model_dir_for_tokenizer ./model/YukinoStuki/Qwen2.5-0.5B-Plus-LLM --batch --overwrite_jsonl --debug_first_n 5 --debug_random_n 5`\n\n"
                            "è¾“å‡ºæ˜¾ç¤ºåœ¨ä¸‹æ–¹ï¼›"
                        )
                        batch_btn = gr.Button("batchæµ‹è¯•", variant="primary")
                        batch_out = gr.Textbox(label="è¾“å‡º", lines=18, max_lines=30, interactive=False)

                    with gr.Tab("RAG"):
                        gr.Markdown(
                            """
- **æœ¬åœ°**ï¼šä¸Šä¼  txt/md ç­‰çº¯æ–‡æœ¬æ–‡ä»¶
- **è”ç½‘**ï¼šæŠ“å–æä¾›çš„ URL å†…å®¹â€\n
"""
                        )
                        rag_enable = gr.Checkbox(value=False, label="å¯ç”¨ RAGï¼ˆæŠŠå‘½ä¸­ç‰‡æ®µæ‹¼åˆ° promptï¼‰")
                        rag_allow_network = gr.Checkbox(value=False, label="å…è®¸è”ç½‘æŠ“å– URLï¼ˆä»…æŠ“å–ä¸‹æ–¹å¡«å†™çš„é“¾æ¥ï¼‰")
                        rag_use_baidu = gr.Checkbox(value=False, label="ä½¿ç”¨ www.baidu.com æœç´¢ç»“æœï¼ˆéœ€å¼€å¯è”ç½‘ï¼‰")
                        rag_urls = gr.Textbox(
                            label="URL åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¯ç©ºï¼‰",
                            placeholder="https://...\nhttps://...",
                            lines=3,
                            max_lines=8,
                        )
                        rag_use_metax_urls = gr.Checkbox(
                            value=True,
                            label="ä½¿ç”¨ metax_url.json å›ºå®šURLåº“ï¼ˆé»˜è®¤å‹¾é€‰ï¼›éœ€å¼€å¯è”ç½‘ä¸”å…³é—­ç™¾åº¦æœç´¢ï¼‰",
                        )
                        rag_files = gr.File(
                            label="æœ¬åœ°èµ„æ–™æ–‡ä»¶ï¼ˆtxt/mdï¼Œæ”¯æŒå¤šé€‰ï¼‰",
                            file_count="multiple",
                        )
                        rag_top_k = gr.Slider(minimum=1, maximum=8, value=3, step=1, label="top_k å‘½ä¸­ç‰‡æ®µ")
                        rag_max_chars = gr.Slider(minimum=300, maximum=6000, value=1800, step=100, label="å‚è€ƒèµ„æ–™æœ€å¤§å­—ç¬¦æ•°")
                        rag_hits = gr.Textbox(label="æœ¬æ¬¡å‘½ä¸­ç‰‡æ®µ", lines=10, max_lines=18, interactive=False)

                    with gr.Tab("åç«¯ä¿¡æ¯"):
                        info_btn = gr.Button("åˆ·æ–°åç«¯ä¿¡æ¯")
                        backend_info_json = gr.Code(label="/info", language="json", value="")
                        env_table = gr.Dataframe(
                            headers=["key", "value"],
                            datatype=["str", "str"],
                            row_count=(0, "dynamic"),
                            col_count=(2, "fixed"),
                            label="åç«¯ç¯å¢ƒå˜é‡ï¼ˆç™½åå•ï¼‰",
                            interactive=False,
                        )

                    with gr.Tab("WebUI è¿æ¥"):
                        gr.Markdown(
                            """- å˜æ›´ `MODEL_ID/MODEL_DIR/USE_VLLM` ç­‰åŠ è½½æœŸå‚æ•°ä»éœ€é‡å¯åç«¯ã€‚
- ç”Ÿæˆå‚æ•°ã€SYSTEM_PROMPT æ”¯æŒè¿è¡Œæ—¶æ›´æ–°ã€‚"""
                        )
                        gr.Dataframe(
                            value=[
                                ["API_BASE_URL", API_BASE_URL],
                                ["API_TIMEOUT", str(API_TIMEOUT)],
                                ["WEBUI_HOST", WEBUI_HOST],
                                ["WEBUI_PORT", str(WEBUI_PORT)],
                                ["WEBUI_SHARE", str(WEBUI_SHARE)],
                            ],
                            headers=["key", "value"],
                            datatype=["str", "str"],
                            row_count=(5, "fixed"),
                            col_count=(2, "fixed"),
                            interactive=False,
                            label="WebUI å‚æ•°",
                        )

        # äº‹ä»¶å¤„ç†
        def user_submit(user_msg, history):
            """å¤„ç†ç”¨æˆ·æäº¤"""
            if not history:
                history = []
            # Gradio 6.x ä½¿ç”¨å­—å…¸æ ¼å¼ï¼›ä¸æ·»åŠ  None å†…å®¹ï¼Œé¿å…åå¤„ç†æŠ¥é”™
            history.append({"role": "user", "content": user_msg})
            return "", history

        def _to_text(content: Any) -> str:
            """å°† Chatbot æ¶ˆæ¯å†…å®¹å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚

            å…¼å®¹ Gradio 6.xï¼šcontent å¯èƒ½æ˜¯ strã€list[dict|str]ã€dictã€‚
            - è‹¥ä¸º list[dict]ï¼šå°è¯•æ‹¼æ¥å…¶ä¸­çš„ 'text' æˆ– 'content' å­—æ®µã€‚
            - è‹¥ä¸º list[str]ï¼šæŒ‰æ¢è¡Œæ‹¼æ¥ã€‚
            - è‹¥ä¸º dictï¼šä¼˜å…ˆå– 'text' æˆ– 'content'ã€‚
            - å…¶ä»–ç±»å‹ï¼šç”¨ str() å…œåº•ã€‚
            """
            if isinstance(content, str):
                return content
            if isinstance(content, list):
                parts: list[str] = []
                for seg in content:
                    if isinstance(seg, dict):
                        t = seg.get("text") or seg.get("content") or ""
                        if isinstance(t, str) and t:
                            parts.append(t)
                    elif isinstance(seg, str):
                        parts.append(seg)
                return "\n".join([p for p in parts if p])
            if isinstance(content, dict):
                t = content.get("text") or content.get("content") or ""
                return t if isinstance(t, str) else str(t)
            return str(content or "")

        def bot_respond(
            history,
            max_new_tokens,
            temperature,
            top_p,
            top_k,
            repetition_penalty,
            frequency_penalty,
            enable_rag,
            allow_network,
            use_baidu_search,
            urls_text,
            use_metax_url_db,
            files,
            rag_topk,
            rag_maxchars,
        ):
            """å¤„ç†æœºå™¨äººå›å¤ï¼ˆå…¼å®¹ Gradio 6.x Chatbot å­—å…¸æ¶ˆæ¯æ ¼å¼ï¼‰"""
            if not history:
                return history, ""

            # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            user_msg = None
            for msg in reversed(history):
                if isinstance(msg, dict) and msg.get("role") == "user":
                    user_msg = _to_text(msg.get("content", ""))
                    break
            if not user_msg:
                return history, ""

            # è‹¥æœ€åä¸æ˜¯ assistant æ¶ˆæ¯æˆ–å…¶ content éå­—ç¬¦ä¸²ï¼Œå…ˆè¿½åŠ å ä½ï¼ˆç©ºä¸²ï¼‰ï¼Œé¿å… None
            if not (isinstance(history[-1], dict) and history[-1].get("role") == "assistant" and isinstance(history[-1].get("content"), str)):
                history.append({"role": "assistant", "content": ""})

            # å¯é€‰ï¼šRAG å¢å¼ºï¼ˆä»… WebUI ä¾§ï¼Œé»˜è®¤å…³é—­ï¼‰
            final_prompt, rag_display = build_rag_context(
                user_msg,
                enable_rag=bool(enable_rag),
                allow_network=bool(allow_network),
                use_baidu_search=bool(use_baidu_search),
                use_metax_url_db=bool(use_metax_url_db),
                urls_text=str(urls_text or ""),
                files=files,
                top_k=int(rag_topk) if rag_topk is not None else 3,
                max_chars=int(rag_maxchars) if rag_maxchars is not None else 1800,
            )

            gen_params = {
                "max_new_tokens": int(max_new_tokens) if max_new_tokens is not None else None,
                "temperature": float(temperature) if temperature is not None else None,
                "top_p": float(top_p) if top_p is not None else None,
                "top_k": int(top_k) if top_k is not None else None,
                "repetition_penalty": float(repetition_penalty) if repetition_penalty is not None else None,
                "frequency_penalty": float(frequency_penalty) if frequency_penalty is not None else None,
            }

            # è°ƒç”¨åç«¯ç”Ÿæˆï¼Œå¹¶é€æ­¥æ›´æ–°æœ€åä¸€æ¡ assistant çš„å†…å®¹
            for response in predict(final_prompt, gen_params=gen_params):
                history[-1]["content"] = response or ""
                yield history, rag_display

        def clear_history():
            """æ¸…ç©ºå¯¹è¯å†å²"""
            return [], ""

        def refresh_health():
            """åˆ·æ–°å¥åº·çŠ¶æ€"""
            _, status = check_api_health()
            return status

        # ç»‘å®šäº‹ä»¶
        submit_btn.click(
            user_submit,
            [user_input, chatbot],
            [user_input, chatbot],
            queue=False,
        ).then(
            bot_respond,
            [
                chatbot,
                ui_max_new_tokens,
                ui_temperature,
                ui_top_p,
                ui_top_k,
                ui_repetition_penalty,
                ui_frequency_penalty,
                rag_enable,
                rag_allow_network,
                rag_use_baidu,
                rag_urls,
                rag_use_metax_urls,
                rag_files,
                rag_top_k,
                rag_max_chars,
            ],
            [chatbot, rag_hits],
        )

        user_input.submit(
            user_submit,
            [user_input, chatbot],
            [user_input, chatbot],
            queue=False,
        ).then(
            bot_respond,
            [
                chatbot,
                ui_max_new_tokens,
                ui_temperature,
                ui_top_p,
                ui_top_k,
                ui_repetition_penalty,
                ui_frequency_penalty,
                rag_enable,
                rag_allow_network,
                rag_use_baidu,
                rag_urls,
                rag_use_metax_urls,
                rag_files,
                rag_top_k,
                rag_max_chars,
            ],
            [chatbot, rag_hits],
        )

        clear_btn.click(clear_history, None, [chatbot, user_input], queue=False)

        info_btn.click(fetch_backend_info, None, [backend_info_json, env_table], queue=False)

        sys_prompt_reload_btn.click(fetch_system_prompt, None, sys_prompt_box, queue=False)
        sys_prompt_apply_btn.click(apply_system_prompt, [sys_prompt_box], sys_prompt_status, queue=False)

        batch_btn.click(run_batch_test, None, batch_out, queue=True)

        # åˆå§‹åŠ è½½ä¸€æ¬¡ /info
        demo.load(fetch_backend_info, None, [backend_info_json, env_table], queue=False)
        demo.load(fetch_system_prompt, None, sys_prompt_box, queue=False)

    return demo


def main():
    """å¯åŠ¨ WebUI"""
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ Qwen2.5-0.5B Plus WebUI")
    print(f"åç«¯ API: {API_BASE_URL}")
    print(f"ç›‘å¬åœ°å€: {WEBUI_HOST}:{WEBUI_PORT}")
    print(f"å…¬å¼€åˆ†äº«: {'æ˜¯' if WEBUI_SHARE else 'å¦'}")
    print("=" * 60)

    # æ£€æŸ¥åç«¯å¯ç”¨æ€§
    is_healthy, health_msg = check_api_health()
    if not is_healthy:
        print(f"\nâš ï¸  è­¦å‘Š: {health_msg}")
        print("è¯·ç¡®ä¿ serve.py å·²å¯åŠ¨å¹¶ç›‘å¬åœ¨", API_BASE_URL)
        print("\nç»§ç»­å¯åŠ¨ WebUI (åç«¯å¯ä»¥ç¨åå¯åŠ¨)...\n")

    demo = create_ui()
    demo.launch(
        server_name=WEBUI_HOST,
        server_port=WEBUI_PORT,
        share=WEBUI_SHARE,
        theme=gr.themes.Soft(),
    )


if __name__ == "__main__":
    main()
