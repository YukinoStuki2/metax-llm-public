#!/usr/bin/env python3
"""
è½»é‡çº§ Gradio WebUI for serve.py
ç›´æ¥è°ƒç”¨ serve.py çš„ FastAPI æ¥å£è¿›è¡Œæ¨ç†
"""

import os
import sys
import requests
import gradio as gr
import json
from typing import Optional, Iterator, Any

# é…ç½®
API_BASE_URL = os.environ.get("API_BASE_URL", "http://127.0.0.1:8000")
API_TIMEOUT = int(os.environ.get("API_TIMEOUT", "360"))
WEBUI_PORT = int(os.environ.get("WEBUI_PORT", "7860"))
WEBUI_HOST = os.environ.get("WEBUI_HOST", "0.0.0.0")
WEBUI_SHARE = os.environ.get("WEBUI_SHARE", "0") == "1"


def _pretty_json(obj: Any) -> str:
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        return str(obj)


def check_api_health() -> tuple[bool, str]:
    """æ£€æŸ¥åç«¯ API å¥åº·çŠ¶æ€"""
    try:
        response = requests.get(f"{API_BASE_URL}/", timeout=10)
        if response.status_code == 200:
            data = response.json()
            status = data.get("status", "ok")
            return True, f"âœ… åç«¯çŠ¶æ€: {status}"
        else:
            return False, f"âŒ åç«¯è¿”å›é”™è¯¯: HTTP {response.status_code}"
    except requests.exceptions.ConnectionError:
        return False, f"âŒ æ— æ³•è¿æ¥åˆ°åç«¯ {API_BASE_URL}"
    except Exception as e:
        return False, f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"


def predict(user_input: str, gen_params: Optional[dict] = None) -> Iterator[str]:
    """è°ƒç”¨åç«¯ API è¿›è¡Œæ¨ç†"""
    if not isinstance(user_input, str):
        user_input = str(user_input)
    if not user_input or not user_input.strip():
        yield "âš ï¸ è¯·è¾“å…¥é—®é¢˜"
        return

    # æ£€æŸ¥ API å¯ç”¨æ€§
    is_healthy, health_msg = check_api_health()
    if not is_healthy:
        yield health_msg
        return

    try:
        payload = {"prompt": user_input.strip()}
        if isinstance(gen_params, dict):
            # ä»…é€ä¼ é None çš„å‚æ•°ï¼Œé¿å…æ±¡æŸ“é»˜è®¤è¡Œä¸º
            for k, v in gen_params.items():
                if v is None:
                    continue
                payload[k] = v

        # è°ƒç”¨ /predict æ¥å£
        response = requests.post(
            f"{API_BASE_URL}/predict",
            json=payload,
            timeout=API_TIMEOUT,
        )
        response.raise_for_status()

        result = response.json()
        answer = result.get("response", "")

        if not answer:
            yield "âš ï¸ æ¨¡å‹è¿”å›äº†ç©ºç­”æ¡ˆ"
        else:
            yield answer

    except requests.exceptions.Timeout:
        yield f"âŒ è¯·æ±‚è¶…æ—¶ (>{API_TIMEOUT}s)"
    except requests.exceptions.RequestException as e:
        yield f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}"
    except Exception as e:
        yield f"âŒ æ¨ç†å‡ºé”™: {str(e)}"


def fetch_backend_info() -> tuple[str, list[list[str]]]:
    """è·å–åç«¯ /info ä¿¡æ¯ï¼Œå¹¶è½¬æ¢ä¸ºé€‚åˆ UI å±•ç¤ºçš„æ•°æ®ã€‚"""
    try:
        r = requests.get(f"{API_BASE_URL}/info", timeout=10)
        if r.status_code != 200:
            return f"âŒ /info è¿”å› HTTP {r.status_code}", []
        info = r.json()
        env_map = info.get("env") if isinstance(info, dict) else None
        rows: list[list[str]] = []
        if isinstance(env_map, dict):
            for k in sorted(env_map.keys()):
                v = env_map.get(k)
                rows.append([str(k), "" if v is None else str(v)])
        return _pretty_json(info), rows
    except Exception as e:
        return f"âŒ è·å– /info å¤±è´¥: {e}", []


def create_ui():
    """åˆ›å»º Gradio ç•Œé¢"""
    # æ£€æŸ¥åç«¯çŠ¶æ€
    is_healthy, health_status = check_api_health()

    with gr.Blocks(title="Qwen2.5-0.5B Plus WebUI") as demo:
        gr.Markdown(
            f"""
# ğŸ¤– Qwen2.5-0.5B Plus WebUI

**åç«¯åœ°å€**: `{API_BASE_URL}`  
**çŠ¶æ€**: {health_status}

---
"""
        )

        with gr.Row():
            with gr.Column(scale=7):
                chatbot = gr.Chatbot(label="å¯¹è¯", height=520)
                user_input = gr.Textbox(
                    label="è¾“å…¥",
                    placeholder="è¾“å…¥é—®é¢˜åå›è½¦æˆ–ç‚¹å‡»å‘é€â€¦",
                    lines=3,
                    max_lines=10,
                )
                with gr.Row():
                    submit_btn = gr.Button("å‘é€", variant="primary", scale=2)
                    clear_btn = gr.Button("æ¸…ç©º", scale=1)

            with gr.Column(scale=5):
                with gr.Accordion("ç”Ÿæˆå‚æ•°ï¼ˆå•æ¬¡è¯·æ±‚ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯åç«¯ï¼‰", open=True):
                    ui_max_new_tokens = gr.Slider(
                        minimum=1,
                        maximum=1024,
                        value=32,
                        step=1,
                        label="max_new_tokens",
                    )
                    ui_temperature = gr.Slider(
                        minimum=0.0,
                        maximum=1.5,
                        value=0.0,
                        step=0.01,
                        label="temperature (0=è´ªå¿ƒ)",
                    )
                    ui_top_p = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        value=1.0,
                        step=0.01,
                        label="top_p",
                    )
                    ui_top_k = gr.Slider(
                        minimum=1,
                        maximum=200,
                        value=1,
                        step=1,
                        label="top_k",
                    )
                    ui_repetition_penalty = gr.Slider(
                        minimum=1.0,
                        maximum=1.5,
                        value=1.05,
                        step=0.01,
                        label="repetition_penalty",
                    )
                    ui_frequency_penalty = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        value=0.1,
                        step=0.01,
                        label="frequency_penalty",
                    )

                with gr.Accordion("åç«¯è¿è¡Œä¿¡æ¯ / ç¯å¢ƒå˜é‡ï¼ˆæ¥è‡ª /infoï¼‰", open=False):
                    info_btn = gr.Button("åˆ·æ–°åç«¯ä¿¡æ¯")
                    backend_info_json = gr.Code(label="/info", language="json", value="")
                    env_table = gr.Dataframe(
                        headers=["key", "value"],
                        datatype=["str", "str"],
                        row_count=(0, "dynamic"),
                        col_count=(2, "fixed"),
                        label="åç«¯ç¯å¢ƒå˜é‡ï¼ˆç™½åå•ï¼‰",
                        interactive=False,
                    )

                with gr.Accordion("æœ¬ WebUI è¿æ¥ä¿¡æ¯", open=False):
                    gr.Markdown(
                        """- åªè¦åç«¯æ”¯æŒæ‰©å±•å­—æ®µï¼Œå°±èƒ½åšåˆ°**ä¸é‡å¯**å•æ¬¡è°ƒå‚ã€‚
- å˜æ›´ `MODEL_ID/MODEL_DIR/USE_VLLM` è¿™ç±»â€œåŠ è½½æœŸå‚æ•°â€ä»ç„¶éœ€è¦é‡å¯åç«¯ã€‚"""
                    )
                    gr.Dataframe(
                        value=[
                            ["API_BASE_URL", API_BASE_URL],
                            ["API_TIMEOUT", str(API_TIMEOUT)],
                            ["WEBUI_HOST", WEBUI_HOST],
                            ["WEBUI_PORT", str(WEBUI_PORT)],
                            ["WEBUI_SHARE", str(WEBUI_SHARE)],
                        ],
                        headers=["key", "value"],
                        datatype=["str", "str"],
                        row_count=(5, "fixed"),
                        col_count=(2, "fixed"),
                        interactive=False,
                        label="WebUI å‚æ•°",
                    )

        # äº‹ä»¶å¤„ç†
        def user_submit(user_msg, history):
            """å¤„ç†ç”¨æˆ·æäº¤"""
            if not history:
                history = []
            # Gradio 6.x ä½¿ç”¨å­—å…¸æ ¼å¼ï¼›ä¸æ·»åŠ  None å†…å®¹ï¼Œé¿å…åå¤„ç†æŠ¥é”™
            history.append({"role": "user", "content": user_msg})
            return "", history

        def _to_text(content: Any) -> str:
            """å°† Chatbot æ¶ˆæ¯å†…å®¹å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚

            å…¼å®¹ Gradio 6.xï¼šcontent å¯èƒ½æ˜¯ strã€list[dict|str]ã€dictã€‚
            - è‹¥ä¸º list[dict]ï¼šå°è¯•æ‹¼æ¥å…¶ä¸­çš„ 'text' æˆ– 'content' å­—æ®µã€‚
            - è‹¥ä¸º list[str]ï¼šæŒ‰æ¢è¡Œæ‹¼æ¥ã€‚
            - è‹¥ä¸º dictï¼šä¼˜å…ˆå– 'text' æˆ– 'content'ã€‚
            - å…¶ä»–ç±»å‹ï¼šç”¨ str() å…œåº•ã€‚
            """
            if isinstance(content, str):
                return content
            if isinstance(content, list):
                parts: list[str] = []
                for seg in content:
                    if isinstance(seg, dict):
                        t = seg.get("text") or seg.get("content") or ""
                        if isinstance(t, str) and t:
                            parts.append(t)
                    elif isinstance(seg, str):
                        parts.append(seg)
                return "\n".join([p for p in parts if p])
            if isinstance(content, dict):
                t = content.get("text") or content.get("content") or ""
                return t if isinstance(t, str) else str(t)
            return str(content or "")

        def bot_respond(
            history,
            max_new_tokens,
            temperature,
            top_p,
            top_k,
            repetition_penalty,
            frequency_penalty,
        ):
            """å¤„ç†æœºå™¨äººå›å¤ï¼ˆå…¼å®¹ Gradio 6.x Chatbot å­—å…¸æ¶ˆæ¯æ ¼å¼ï¼‰"""
            if not history:
                return history

            # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            user_msg = None
            for msg in reversed(history):
                if isinstance(msg, dict) and msg.get("role") == "user":
                    user_msg = _to_text(msg.get("content", ""))
                    break
            if not user_msg:
                return history

            # è‹¥æœ€åä¸æ˜¯ assistant æ¶ˆæ¯æˆ–å…¶ content éå­—ç¬¦ä¸²ï¼Œå…ˆè¿½åŠ å ä½ï¼ˆç©ºä¸²ï¼‰ï¼Œé¿å… None
            if not (isinstance(history[-1], dict) and history[-1].get("role") == "assistant" and isinstance(history[-1].get("content"), str)):
                history.append({"role": "assistant", "content": ""})

            gen_params = {
                "max_new_tokens": int(max_new_tokens) if max_new_tokens is not None else None,
                "temperature": float(temperature) if temperature is not None else None,
                "top_p": float(top_p) if top_p is not None else None,
                "top_k": int(top_k) if top_k is not None else None,
                "repetition_penalty": float(repetition_penalty) if repetition_penalty is not None else None,
                "frequency_penalty": float(frequency_penalty) if frequency_penalty is not None else None,
            }

            # è°ƒç”¨åç«¯ç”Ÿæˆï¼Œå¹¶é€æ­¥æ›´æ–°æœ€åä¸€æ¡ assistant çš„å†…å®¹
            for response in predict(user_msg, gen_params=gen_params):
                history[-1]["content"] = response or ""
                yield history

        def clear_history():
            """æ¸…ç©ºå¯¹è¯å†å²"""
            return [], ""

        def refresh_health():
            """åˆ·æ–°å¥åº·çŠ¶æ€"""
            _, status = check_api_health()
            return status

        # ç»‘å®šäº‹ä»¶
        submit_btn.click(
            user_submit,
            [user_input, chatbot],
            [user_input, chatbot],
            queue=False,
        ).then(
            bot_respond,
            [
                chatbot,
                ui_max_new_tokens,
                ui_temperature,
                ui_top_p,
                ui_top_k,
                ui_repetition_penalty,
                ui_frequency_penalty,
            ],
            chatbot,
        )

        user_input.submit(
            user_submit,
            [user_input, chatbot],
            [user_input, chatbot],
            queue=False,
        ).then(
            bot_respond,
            [
                chatbot,
                ui_max_new_tokens,
                ui_temperature,
                ui_top_p,
                ui_top_k,
                ui_repetition_penalty,
                ui_frequency_penalty,
            ],
            chatbot,
        )

        clear_btn.click(clear_history, None, [chatbot, user_input], queue=False)

        info_btn.click(fetch_backend_info, None, [backend_info_json, env_table], queue=False)

        # åˆå§‹åŠ è½½ä¸€æ¬¡ /info
        demo.load(fetch_backend_info, None, [backend_info_json, env_table], queue=False)

    return demo


def main():
    """å¯åŠ¨ WebUI"""
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨ Qwen2.5-0.5B Plus WebUI")
    print(f"åç«¯ API: {API_BASE_URL}")
    print(f"ç›‘å¬åœ°å€: {WEBUI_HOST}:{WEBUI_PORT}")
    print(f"å…¬å¼€åˆ†äº«: {'æ˜¯' if WEBUI_SHARE else 'å¦'}")
    print("=" * 60)

    # æ£€æŸ¥åç«¯å¯ç”¨æ€§
    is_healthy, health_msg = check_api_health()
    if not is_healthy:
        print(f"\nâš ï¸  è­¦å‘Š: {health_msg}")
        print("è¯·ç¡®ä¿ serve.py å·²å¯åŠ¨å¹¶ç›‘å¬åœ¨", API_BASE_URL)
        print("\nç»§ç»­å¯åŠ¨ WebUI (åç«¯å¯ä»¥ç¨åå¯åŠ¨)...\n")

    demo = create_ui()
    demo.launch(
        server_name=WEBUI_HOST,
        server_port=WEBUI_PORT,
        share=WEBUI_SHARE,
        theme=gr.themes.Soft(),
    )


if __name__ == "__main__":
    main()
